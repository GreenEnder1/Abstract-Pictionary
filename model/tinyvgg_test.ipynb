{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor # converts PIL image or numpy array into tensors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TinyVGG Model\n",
    "\n",
    "This is the model based off of the tinyvgg architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyVGG(nn.Module):\n",
    "  def __init__(self,\n",
    "               input_shape: int,\n",
    "               hidden_units: int,\n",
    "               output_shape: int):\n",
    "    super().__init__()\n",
    "    self.conv_block_1 = nn.Sequential(nn.Conv2d(in_channels=input_shape,\n",
    "                                                out_channels=hidden_units,\n",
    "                                                kernel_size=3,\n",
    "                                                stride=1,\n",
    "                                                padding=1),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Conv2d(in_channels=hidden_units,\n",
    "                                                out_channels=hidden_units,\n",
    "                                                kernel_size=3,\n",
    "                                                stride=1,\n",
    "                                                padding=1),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.MaxPool2d(kernel_size=2,\n",
    "                                                   stride=2) # default stride is same as kernel size\n",
    "                                      )\n",
    "    self.conv_block_2 = nn.Sequential(nn.Conv2d(in_channels=hidden_units,\n",
    "                                                out_channels=hidden_units,\n",
    "                                                kernel_size=3,\n",
    "                                                stride=1,\n",
    "                                                padding=1),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Conv2d(in_channels=hidden_units,\n",
    "                                                out_channels=hidden_units,\n",
    "                                                kernel_size=3,\n",
    "                                                stride=1,\n",
    "                                                padding=1),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.MaxPool2d(kernel_size=2,\n",
    "                                                   stride=2)\n",
    "                                      )\n",
    "    self.classifier = nn.Sequential(nn.Flatten(),\n",
    "                                      nn.Linear(in_features=hidden_units, # get from errors\n",
    "                                                out_features=output_shape))\n",
    "\n",
    "    def forward(self,x):\n",
    "      x = self.conv_block_1(x)\n",
    "      print(x.shape)\n",
    "      x = self.conv_block_2(x)\n",
    "      print(x.shape)\n",
    "      x = self.classifier(x)\n",
    "      print(x.shape)\n",
    "      return x # writing this in one line would benefit from operator fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "# Dataloader\n",
    "1000 images per class,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transforms.Resize(size=(64, 64)), # resize to 64x64 so we can use tinyVGG architecture\n",
    "                                     transforms.RandomHorizontalFlip(p=0.5), # randomly flips an image horizontally\n",
    "                                     transforms.ToTensor()]) # transforms to tensor\n",
    "data_transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_paths, transform, n=3, seed=42):\n",
    "  \"\"\"\n",
    "  selects random images from a path of images, and loads/transforms them and plots the original vs transformed version\n",
    "  \"\"\"\n",
    "  if seed:\n",
    "    random.seed(seed)\n",
    "  random_image_paths = random.sample(image_paths, k=n)\n",
    "  for image_path in random_image_paths:\n",
    "    with Image.open(image_path) as f:\n",
    "      fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "      ax[0].imshow(f)\n",
    "      ax[0].set_title(f'Original\\nSize: {f.size}')\n",
    "      ax[0].axis(False)\n",
    "\n",
    "      transformed_image = transform(f).permute(1, 2, 0)\n",
    "      ax[1].imshow(transformed_image)\n",
    "      ax[1].set_title(f'Transformed\\nSize: {transformed_image.shape}')\n",
    "      ax[1].axis('off')\n",
    "\n",
    "      fig.suptitle(f'Class: {image_path.parent.stem}', fontsize=16)\n",
    "\n",
    "plot_transformed_images(image_paths=image_path_list,\n",
    "                        transform=data_transform,\n",
    "                        n=3,\n",
    "                        seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
